{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from PIL import Image \n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sub_path(path):\n",
    "    sub_path = []\n",
    "    if isinstance(path, list):\n",
    "        for p in path:\n",
    "            if os.path.isdir(p):\n",
    "                for file in os.listdir(p):\n",
    "                    sub_path.append(os.path.join(p, file))\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        for file in os.listdir(path):\n",
    "            sub_path.append(os.path.join(path, file))\n",
    "    return sub_path\n",
    "\n",
    "def divide_list(list, n):\n",
    "    for i in range(0, len(list), n):\n",
    "        yield list[i:i + n]\n",
    "        \n",
    "def std(input):\n",
    "    if input.max() == 0:\n",
    "        return input\n",
    "    else:\n",
    "        result = (input-input.min()) / (input.max()-input.min())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['IR_drop_features_decompressed/power_i', 'IR_drop_features_decompressed/power_s', \n",
    "        'IR_drop_features_decompressed/power_sca', 'IR_drop_features_decompressed/power_all']\n",
    "label_list = ['IR_drop_features_decompressed/IR_drop']\n",
    "\n",
    "datapath = './CircuitNet-N28/'\n",
    "# datapath = '../../CircuitNet/CircuitNet-N28/'\n",
    "name_list = get_sub_path(os.path.join(datapath, feature_list[-1]))\n",
    "n_list = divide_list(name_list, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_size=(224, 224)):\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_dirs = ['power_i', 'power_s', 'power_sca', 'Power_all']\n",
    "        self.label_dir = 'IR_drop'\n",
    "        self.target_size = target_size\n",
    "        # Collect all the feature and label file paths\n",
    "        self.data = []\n",
    "        i=0\n",
    "        for case_name in os.listdir(os.path.join(root_dir, self.feature_dirs[0])):\n",
    "            feature_paths = [os.path.join(root_dir, feature_dir, case_name) for feature_dir in self.feature_dirs]\n",
    "            label_path = os.path.join(root_dir, self.label_dir, case_name)\n",
    "            if all(os.path.exists(fp) for fp in feature_paths) and os.path.exists(label_path):\n",
    "                self.data.append((feature_paths, label_path))\n",
    "            i+=1\n",
    "            if i>100:\n",
    "                break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature_paths, label_path = self.data[idx]\n",
    "        features = []\n",
    "        \n",
    "        for fp in feature_paths:\n",
    "            feature = np.load(fp)\n",
    "            feature = torch.tensor(feature, dtype=torch.float32)\n",
    "            feature = F.interpolate(feature.unsqueeze(0).unsqueeze(0), size=self.target_size, mode='nearest').squeeze(0).squeeze(0)\n",
    "            feature = std(feature)\n",
    "            features.append(feature)\n",
    "            \n",
    "        features = torch.stack(features, dim=0)\n",
    "        \n",
    "        # Load and process label file\n",
    "        label = np.load(label_path)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        label = F.interpolate(label.unsqueeze(0).unsqueeze(0), size=self.target_size, mode='nearest').squeeze(0).squeeze(0)\n",
    "        label = label.clamp(1e-6, 50)\n",
    "        label = (torch.log10(label)+6)/ (np.log10(50)+6)\n",
    "        \n",
    "        return features, label\n",
    "    \n",
    "root_dir = './CircuitNet-N28/IR_drop_features_decompressed/'\n",
    "dataset = PowerDataset(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([4, 4, 224, 224]) torch.Size([4, 224, 224])\n",
      "torch.Size([1, 4, 224, 224]) torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "\n",
    "for features, labels in dataloader:\n",
    "    print(features.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swintransformer import *\n",
    "\n",
    "model_name = 'swin_base_patch4_window7_224'\n",
    "model = init_model(model_name, input_channels=4, num_classes=0, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     ir_prediction = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ir_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:38<01:48,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[26](26/200): Loss: 5.3629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:36<01:43,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[52](52/200): Loss: 5.3117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:36<01:43,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[78](78/200): Loss: 5.2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:31<01:51,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[100](100/200): Loss: 4.4725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:36<01:44,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[126](126/200): Loss: 5.2859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:36<01:44,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[152](152/200): Loss: 5.2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:36<01:44,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[178](178/200): Loss: 5.3117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:32<01:53,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iters[200](200/200): Loss: 4.4787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import utils.losses as losses\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from math import cos, pi\n",
    "model.train()\n",
    "\n",
    "def checkpoint(model, epoch, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    model_out_path = f\"./{save_path}/swinTransformer_iters_{epoch}.pth\"\n",
    "    torch.save({'state_dict': model.state_dict()}, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "\n",
    "class CosineRestartLr(object):\n",
    "    def __init__(self,\n",
    "                 base_lr,\n",
    "                 periods,\n",
    "                 restart_weights = [1],\n",
    "                 min_lr = None,\n",
    "                 min_lr_ratio = None):\n",
    "        self.periods = periods\n",
    "        self.min_lr = min_lr\n",
    "        self.min_lr_ratio = min_lr_ratio\n",
    "        self.restart_weights = restart_weights\n",
    "        super().__init__()\n",
    "\n",
    "        self.cumulative_periods = [\n",
    "            sum(self.periods[0:i + 1]) for i in range(0, len(self.periods))\n",
    "        ]\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "\n",
    "    def annealing_cos(self, start: float,\n",
    "                    end: float,\n",
    "                    factor: float,\n",
    "                    weight: float = 1.) -> float:\n",
    "        cos_out = cos(pi * factor) + 1\n",
    "        return end + 0.5 * weight * (start - end) * cos_out\n",
    "\n",
    "    def get_position_from_periods(self, iteration: int, cumulative_periods):\n",
    "        for i, period in enumerate(cumulative_periods):\n",
    "            if iteration < period:\n",
    "                return i\n",
    "        raise ValueError(f'Current iteration {iteration} exceeds '\n",
    "                        f'cumulative_periods {cumulative_periods}')\n",
    "\n",
    "\n",
    "    def get_lr(self, iter_num, base_lr: float):\n",
    "        target_lr = self.min_lr  # type:ignore\n",
    "\n",
    "        idx = self.get_position_from_periods(iter_num, self.cumulative_periods)\n",
    "        current_weight = self.restart_weights[idx]\n",
    "        nearest_restart = 0 if idx == 0 else self.cumulative_periods[idx - 1]\n",
    "        current_periods = self.periods[idx]\n",
    "\n",
    "        alpha = min((iter_num - nearest_restart) / current_periods, 1)\n",
    "        return self.annealing_cos(base_lr, target_lr, alpha, current_weight)\n",
    "\n",
    "    \n",
    "    def _set_lr(self, optimizer, lr_groups):\n",
    "        if isinstance(optimizer, dict):\n",
    "            for k, optim in optimizer.items():\n",
    "                for param_group, lr in zip(optim.param_groups, lr_groups[k]):\n",
    "                    param_group['lr'] = lr\n",
    "        else:\n",
    "            for param_group, lr in zip(optimizer.param_groups,\n",
    "                                        lr_groups):\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "    def get_regular_lr(self, iter_num):\n",
    "        return [self.get_lr(iter_num, _base_lr) for _base_lr in self.base_lr]  # iters\n",
    "\n",
    "    def set_init_lr(self, optimizer):\n",
    "        for group in optimizer.param_groups:  # type: ignore\n",
    "            group.setdefault('initial_lr', group['lr'])\n",
    "            self.base_lr = [group['initial_lr'] for group in optimizer.param_groups  # type: ignore\n",
    "        ]\n",
    "\n",
    "\n",
    "# Build loss\n",
    "loss = losses.__dict__['L1Loss']()\n",
    "\n",
    "arg_dict = {'task': 'irdrop_mavi', 'save_path': 'work_dir/irdrop_mavi/', 'pretrained': None, 'max_iters':200, 'plot_roc': False, 'arg_file': None, 'cpu': True, 'dataroot': 'CircuitNet-N28/training_set/IR_drop', 'ann_file_train': './files/train_N28.csv', 'ann_file_test': './files/test_N28.csv', 'dataset_type': 'IRDropDataset', 'batch_size': 2, 'model_type': 'MAVI', 'in_channels': 1, 'out_channels': 4, 'lr': 0.0002, 'weight_decay': 0.01, 'loss_type': 'L1Loss', 'eval_metric': ['NRMS', 'SSIM'], 'threshold': 0.9885, 'ann_file': './files/train_N28.csv', 'test_mode': False}\n",
    "\n",
    "# Build Optimzer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=arg_dict['lr'],  betas=(0.9, 0.999), weight_decay=arg_dict['weight_decay'])\n",
    "\n",
    "# Build lr scheduler\n",
    "cosine_lr = CosineRestartLr(arg_dict['lr'], [arg_dict['max_iters']], [1], 1e-7)\n",
    "cosine_lr.set_init_lr(optimizer)\n",
    "\n",
    "epoch_loss = 0\n",
    "iter_num = 0\n",
    "print_freq = 100\n",
    "# save_freq = 10000\n",
    "save_freq = 1000\n",
    "\n",
    "while iter_num < arg_dict['max_iters']:\n",
    "    with tqdm(total=print_freq) as bar:\n",
    "        # for feature, label, _ in dataset:     \n",
    "        for feature, label in dataloader:   \n",
    "            if arg_dict['cpu']:\n",
    "                input, target = feature, label\n",
    "            else:\n",
    "                input, target = feature.cuda(), label.cuda()\n",
    "\n",
    "            regular_lr = cosine_lr.get_regular_lr(iter_num)\n",
    "            cosine_lr._set_lr(optimizer, regular_lr)\n",
    "\n",
    "            prediction = model(input)\n",
    "            # print(input.shape)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction = prediction.squeeze(1)\n",
    "            pixel_loss = loss(prediction, target)\n",
    "\n",
    "            epoch_loss += pixel_loss.item()\n",
    "            pixel_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iter_num += 1\n",
    "            \n",
    "            bar.update(1)\n",
    "\n",
    "            if iter_num % print_freq == 0:\n",
    "                break\n",
    "\n",
    "    print(\"===> Iters[{}]({}/{}): Loss: {:.4f}\".format(iter_num, iter_num, arg_dict['max_iters'], epoch_loss / print_freq))\n",
    "    if iter_num % save_freq == 0:\n",
    "        checkpoint(model, iter_num, arg_dict['save_path'])\n",
    "    epoch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'swin_base_patch4_window7_224' is available in pretrained models.\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "avail_pretrained_models = timm.list_models()\n",
    "\n",
    "if 'swin_base_patch4_window7_224' in avail_pretrained_models:\n",
    "    print(\"'swin_base_patch4_window7_224' is available in pretrained models.\")\n",
    "else:\n",
    "    print(\"'swin_base_patch4_window7_224' is not available in pretrained models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Swin models: ['swin_base_patch4_window7_224.ms_in1k', 'swin_base_patch4_window7_224.ms_in22k', 'swin_base_patch4_window7_224.ms_in22k_ft_in1k', 'swin_base_patch4_window12_384.ms_in1k', 'swin_base_patch4_window12_384.ms_in22k', 'swin_base_patch4_window12_384.ms_in22k_ft_in1k', 'swin_large_patch4_window7_224.ms_in22k', 'swin_large_patch4_window7_224.ms_in22k_ft_in1k', 'swin_large_patch4_window12_384.ms_in22k', 'swin_large_patch4_window12_384.ms_in22k_ft_in1k', 'swin_s3_base_224.ms_in1k', 'swin_s3_small_224.ms_in1k', 'swin_s3_tiny_224.ms_in1k', 'swin_small_patch4_window7_224.ms_in1k', 'swin_small_patch4_window7_224.ms_in22k', 'swin_small_patch4_window7_224.ms_in22k_ft_in1k', 'swin_tiny_patch4_window7_224.ms_in1k', 'swin_tiny_patch4_window7_224.ms_in22k', 'swin_tiny_patch4_window7_224.ms_in22k_ft_in1k', 'swinv2_base_window8_256.ms_in1k', 'swinv2_base_window12_192.ms_in22k', 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k', 'swinv2_base_window12to24_192to384.ms_in22k_ft_in1k', 'swinv2_base_window16_256.ms_in1k', 'swinv2_cr_small_224.sw_in1k', 'swinv2_cr_small_ns_224.sw_in1k', 'swinv2_cr_tiny_ns_224.sw_in1k', 'swinv2_large_window12_192.ms_in22k', 'swinv2_large_window12to16_192to256.ms_in22k_ft_in1k', 'swinv2_large_window12to24_192to384.ms_in22k_ft_in1k', 'swinv2_small_window8_256.ms_in1k', 'swinv2_small_window16_256.ms_in1k', 'swinv2_tiny_window8_256.ms_in1k', 'swinv2_tiny_window16_256.ms_in1k']\n"
     ]
    }
   ],
   "source": [
    "swin_models = [model for model in avail_pretrained_models if 'swin' in model]\n",
    "print(\"Available Swin models:\", swin_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
